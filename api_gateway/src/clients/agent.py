"""
AgentClient module for interacting with the agent API service.

This module provides a client for performing agent-related operations,
including streaming responses from the agent model and managing conversation
memory. All methods use HTTP requests (synchronous or asynchronous) and
leverage `BaseClient` for consistent response handling.

Classes:
    AgentClient: Client for interacting with agent endpoints, streaming
        responses, and managing memory.
"""

import httpx
from uuid import UUID
from typing import AsyncGenerator

import requests

from clients.base import BaseClient


class AgentClient(BaseClient):
    """
    Client for interacting with the agent API service.

    Provides methods to:
    - Stream agent responses asynchronously for a given question.
    - Fetch conversation memory for a user session.
    - Persist conversation memory to the backend.

    Inherits from:
        BaseClient: Provides `_handle_response()` for consistent response parsing.
    """

    @staticmethod
    async def stream(
        question: str,
        user_id: int,
        session_id: UUID,
        file_name: str,
        storage_uri: str,
        dataset_summary: str,
        url: str = "http://127.0.0.1:8005/api/v1/agent/stream",
    ) -> AsyncGenerator[str, None]:
        """
        Stream the agent's response to a question asynchronously.

        This method sends a POST request with question and session context
        to the agent service, and yields chunks of text as they arrive.

        Args:
            question: User's query to the agent.
            user_id: Identifier of the user.
            session_id: Identifier of the current session.
            file_name: Name of the file associated with the session.
            storage_uri: Path or URI to the dataset or file storage.
            dataset_summary: Summary of dataset content/context.
            url: API endpoint for streaming agent responses.

        Yields:
            str: Chunks of text generated by the agent in real-time.

        Raises:
            httpx.HTTPStatusError: If the request fails.
        """

        # Prepare payload with session and question context
        payload = {
            "question": question,
            "user_id": user_id,
            "session_id": str(session_id),
            "file_name": file_name,
            "storage_uri": storage_uri,
            "dataset_summary": dataset_summary,
        }

        # Use httpx.AsyncClient for streaming responses
        async with httpx.AsyncClient(timeout=None) as client:
            async with client.stream("POST", url, json=payload) as response:
                # Raise exception for HTTP errors
                response.raise_for_status()
                # Yield chunks of text as they arrive from the stream
                async for chunk in response.aiter_text():
                    if chunk:
                        yield chunk

    @staticmethod
    def get_conversation_memory(
        user_id: int,
        session_id: UUID,
        file_name: str,
        storage_uri: str,
        url: str = "http://127.0.0.1:8005/api/v1/memory/",
    ):
        """
        Fetch conversation history for a given user session.

        Sends a synchronous GET request with query parameters to retrieve
        the agent's conversation memory.

        Args:
            user_id: Identifier of the user.
            session_id: Identifier of the current session.
            file_name: Name of the file associated with the session.
            storage_uri: Path or URI to the dataset or file storage.
            url: API endpoint for retrieving conversation memory.

        Returns:
            dict: Parsed JSON response containing conversation history.
        """

        # Prepare query parameters for GET request
        params = {
            "user_id": user_id,
            "session_id": str(session_id),
            "file_name": file_name,
            "storage_uri": storage_uri,
        }

        # Send GET request to agent memory endpoint
        response = requests.get(url, params=params)

        return AgentClient._handle_response(response)

    @staticmethod
    def save_memory(
        user_id: int,
        session_id: UUID,
        file_name: str,
        url="http://127.0.0.1:8005/api/v1/memory/",
    ):
        """
        Persist cached conversation memory to the backend.

        Sends a synchronous POST request with user and session metadata
        to save the memory state.

        Args:
            user_id: Identifier of the user.
            session_id: Identifier of the current session.
            file_name: Name of the file associated with the session.
            url: API endpoint for saving conversation memory.

        Returns:
            dict: Parsed JSON response confirming memory persistence.
        """
        # Prepare JSON payload for POST request
        data = {
            "user_id": user_id,
            "session_id": str(session_id),
            "file_name": file_name,
        }
        # Send POST request to save memory
        response = requests.post(url=url, json=data)

        # Handle response consistently using BaseClient
        return AgentClient._handle_response(response)
